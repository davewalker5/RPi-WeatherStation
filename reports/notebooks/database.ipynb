{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlparse\n",
    "\n",
    "def construct_query(sql_file, placeholders):\n",
    "    # Read the query file\n",
    "    project_root = get_reports_root_folder()\n",
    "    query_file_path = Path(f\"{project_root}/sql/{sql_file}\").absolute()\n",
    "    with open(query_file_path.absolute(), \"r\") as f:\n",
    "        query = f.read().replace(\"\\n\", \" \")\n",
    "\n",
    "    # Replace all placeholders\n",
    "    for key, value in placeholders.items():\n",
    "        query = query.replace(f\"${key}\", str(value).replace(\"'\", \"''\"))\n",
    "\n",
    "    # Format the query\n",
    "    query = sqlparse.format(query, reindent=True, keyword_case='upper')\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57668d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "DB_PATH_VARIABLE=\"WEATHER_DB\"\n",
    "\n",
    "def query_data(query):\n",
    "    # Connect to the database, execute the query and read the results into a dataframe\n",
    "    database_path = os.environ[DB_PATH_VARIABLE]\n",
    "    connection = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(query, connection, parse_dates=[\"timestamp\"])\n",
    "\n",
    "    # Check there is some data\n",
    "    if not df.shape[0]:\n",
    "        message = f\"No data found\"\n",
    "        raise ValueError(message)\n",
    "\n",
    "    # Convert column titles to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Convert the timestamp string to a date and time - need to remove the trailing Z or it won't parse\n",
    "    df[\"timestamp\"] = (\n",
    "        df[\"timestamp\"]\n",
    "        .str.rstrip(\"Z\")\n",
    "        .pipe(pd.to_datetime, utc=True)\n",
    "    )\n",
    "\n",
    "    # Sort by the timestamp\n",
    "    df.sort_values(\"timestamp\", inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sensor_readings(sensor_name, days=None):\n",
    "    # Construct the path to the query file for the specified sensor\n",
    "    query = construct_query(f\"{sensor_name.casefold()}.sql\", {\n",
    "        \"DAYS\": days if days else \"NULL\"\n",
    "    })\n",
    "\n",
    "    # Run the query to retrieve the data\n",
    "    df = query_data(query)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def merge_sensor_readings(\n",
    "    data_frames: List[pd.DataFrame],\n",
    "    tolerance: str = \"3s\",\n",
    "    direction: str = \"nearest\",\n",
    "    set_index: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge multiple sensor reading DataFrames on a common timestamp column using\n",
    "    pandas.merge_asof, handling slightly misaligned timestamps\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : list of pd.DataFrame\n",
    "        One DataFrame per sensor. All must contain the `on` column\n",
    "        The *first* DataFrame in the list is treated as the \"base\" timeline\n",
    "    tolerance : str or pd.Timedelta, default \"3s\"\n",
    "        Maximum allowed time difference when matching rows (e.g. \"3s\", \"500ms\").\n",
    "    direction : {\"backward\", \"forward\", \"nearest\"}, default \"nearest\"\n",
    "        Direction for merge_asof matching.\n",
    "    set_index : bool, default True\n",
    "        If True, set the merged DataFrame index to the `on` column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Merged DataFrame containing all columns from all input DataFrames.\n",
    "        Unmatched rows (outside tolerance) will have NaNs for missing sensors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Work on copies so we don't mutate the originals\n",
    "    data_frames = [df.copy() for df in data_frames]\n",
    "\n",
    "    # Normalise tolerance to Timedelta\n",
    "    tol = pd.Timedelta(tolerance)\n",
    "\n",
    "    # Reduce the list using merge_asof\n",
    "    def _merge_asof(left: pd.DataFrame, right: pd.DataFrame) -> pd.DataFrame:\n",
    "        return pd.merge_asof(\n",
    "            left,\n",
    "            right,\n",
    "            on=\"timestamp\",\n",
    "            direction=direction,\n",
    "            tolerance=tol\n",
    "        )\n",
    "\n",
    "    merged = reduce(_merge_asof, data_frames)\n",
    "\n",
    "    if set_index:\n",
    "        merged = merged.set_index(\"timestamp\")\n",
    "\n",
    "    return merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
